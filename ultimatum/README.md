# Introduction
This directory contains code to run the Ultimatum Game experiments. 

# Setup
All code is developed with Python 3.9.13. We recommend creating a virtual environment based on the `requirements.txt` file.

```pip install -r requirements.txt```

# Prompts Used in the Paper
The exact prompts used in the paper can be generated by `ultimatum_prompts.py`. You can print out prompts by running the following:

```python ultimatum_prompts.py --condition [low_high_percentage, low_high_payoff, inequity_aversion]```

Add the `--shorter` flag to generate a single prompt followed by an explanation. 

```python ultimatum_prompts.py --condition [low_high_percentage, low_high_payoff, inequity_aversion] --shorter```

# Training Models
We generate our prompts in a batched manner, ask the LLM to annotate our prompts, and save the LLM's answers. We then use those answers as reward signals when training an RL agent. The LLM's responses can be found in the `lm_responses` and `lm_responses_shorter` directories for the 10-example version and the 1-example + explanation version respectively. 

In order to evaluate the LLM's responses, train an RL agent, and evaluate the RL agent's trained behavior, run the following(default reward signals are binary):

```python ultimatum.py --condition [low_high_percentage, low_high_payoff, inequity_aversion]```

Add the `--reward` flag to evaluate and train an RL agent when the LLM reward signals are scaler:

```python ultimatum.py --condition [low_high_percentage, low_high_payoff, inequity_aversion] --reward [binary, scaler]```

Add the `--shorter` flag to evaluate and train an RL agent when the LLM is prompted with 1 example + explanation. 

```python ultimatum.py --condition [low_high_percentage, low_high_payoff, inequity_aversion] --shorter```

# SL Baseline
Code to train the SL baseline reward function for the 10-example version and the 1-example version can be found in `sl.ipynb` and `sl_shorter.ipynb` respectively.

To train an RL agent and evaluate the RL agent's trained behavior run the following:

```python ultimatum.py --condition [low_high_percentage, low_high_payoff, inequity_aversion] --model sl```

Add the `--shorter` flag to evaluate and train an RL agent when the LLM is prompted with 1 example + explanation. 

```python ultimatum.py --condition [low_high_percentage, low_high_payoff, inequity_aversion] --model sl --shorter```
